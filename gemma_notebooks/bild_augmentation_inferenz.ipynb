{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 0. Bibliotheken =====\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoProcessor, Gemma3ForConditionalGeneration\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== 1. Modell & Prozessor =====\n",
    "MODEL_ID = \"../models/Gemma_3_4B/merged_model_batchsize_2/\"\n",
    "model = Gemma3ForConditionalGeneration.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map={\"\": 0},\n",
    "    torch_dtype=torch.bfloat16,\n",
    ").eval()\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(MODEL_ID, use_fast=True)\n",
    "\n",
    "DTYPE = (\n",
    "    torch.bfloat16\n",
    "    if torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n",
    "    else torch.float32\n",
    ")\n",
    "device_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"\n",
    "print(f\"üñ•Ô∏è Torch device: {device_name} | Dtype: {DTYPE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 2. Daten laden =====\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "DATA_PATH = PROJECT_ROOT / \"data\" / \"validation\"\n",
    "dataset = load_from_disk(str(DATA_PATH))\n",
    "print(f\"Dataset geladen: {len(dataset)} Samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 3. Bild-Augmentierung =====\n",
    "augment = A.Compose(\n",
    "    [\n",
    "        A.Rotate(limit=15, p=0.5),\n",
    "        A.RandomBrightnessContrast(0.1, 0.1, p=0.5),\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n",
    "        A.MotionBlur(blur_limit=3, p=0.3),\n",
    "        A.CoarseDropout(max_holes=5, max_h_size=32, max_w_size=32, p=0.3),\n",
    "        A.ImageCompression(70, 100, p=0.3),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 4. CSV-Ausgabe vorbereiten =====\n",
    "OUTPUT_CSV = PROJECT_ROOT / \"data\" / \"llm_answers\" / \"batchsize_2_imageaug_results.csv\"\n",
    "OUTPUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FIELDNAMES = [\"ID\", \"question\", \"correct_answer\", \"model_output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with OUTPUT_CSV.open(\"w\", newline=\"\", encoding=\"utf-8\") as f_out:\n",
    "    writer = csv.DictWriter(f_out, fieldnames=FIELDNAMES)\n",
    "    writer.writeheader()\n",
    "\n",
    "    # ===== 5. Generierung =====\n",
    "    for idx in tqdm(range(len(dataset)), desc=\"Samples\"):\n",
    "        sample = dataset[idx]\n",
    "\n",
    "        # Bild laden und augmentieren\n",
    "        image_rgb = sample[\"image\"].convert(\"RGB\")\n",
    "        aug_np = augment(image=np.array(image_rgb))[\"image\"]\n",
    "        aug_image = Image.fromarray(aug_np)\n",
    "\n",
    "        question = sample[\"question\"]\n",
    "        ground_truth = sample[\"answer\"]\n",
    "        qid = sample.get(\"id\", idx + 1)\n",
    "\n",
    "        # Gemma-Chat-Prompt\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": (\n",
    "                            \"You are a medical pathology expert. \"\n",
    "                            \"Answer strictly based on the visual information in the image. \"\n",
    "                            \"Use short precise terms without explanations.\"\n",
    "                        ),\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\", \"image\": aug_image},\n",
    "                    {\"type\": \"text\", \"text\": question},\n",
    "                ],\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            # Tokenisierung\n",
    "            inputs = processor.apply_chat_template(\n",
    "                messages,\n",
    "                add_generation_prompt=True,\n",
    "                tokenize=True,\n",
    "                return_dict=True,\n",
    "                return_tensors=\"pt\",\n",
    "            ).to(model.device, dtype=DTYPE)\n",
    "\n",
    "            prompt_len = inputs[\"input_ids\"].shape[-1]\n",
    "\n",
    "            # Inferenz\n",
    "            with torch.inference_mode():\n",
    "                gen = model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=100,\n",
    "                    do_sample=False,\n",
    "                )\n",
    "\n",
    "            answer = processor.decode(gen[0][prompt_len:], skip_special_tokens=True).strip()\n",
    "\n",
    "            # CSV-Eintrag\n",
    "            writer.writerow(\n",
    "                {\n",
    "                    \"ID\": qid,\n",
    "                    \"question\": question,\n",
    "                    \"correct_answer\": ground_truth,\n",
    "                    \"model_output\": answer,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        except Exception as err:\n",
    "            print(f\"Fehler bei Sample {qid}: {err}\")\n",
    "            continue\n",
    "\n",
    "print(f\"\\nAlle Ergebnisse gesichert: {OUTPUT_CSV.relative_to(PROJECT_ROOT)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
